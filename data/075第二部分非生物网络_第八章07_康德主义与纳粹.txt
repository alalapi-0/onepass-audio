康德主义与纳粹
⼏千年来，哲学家⼀直想要定义⼀个所谓的终极⽬标，也就是说，这
个⽬标并不需要再看⻬某个更⾼级的⽬标。在哲学上，可能的解决⽅
案分为两⼤派，以哲学术语来说就是义务论与功利主义。义务论（来
⾃希腊⽂的词根deon，意为“责任”）相信，世界上存在所有⼈都应该
遵守的普世道德义务或道德规则。这些规则的重点并不是看⻬某些更
⾼的⽬标，⽽是其本质的良善。如果真的有这样的规则，⽽且我们也
能找到⽅法将其写进计算机程序，就能确保计算机⽹络成为⼀股向善
的⼒量。
但本质的良善到底是什么意思？如果说有谁试过定义“本质的良善”，
代表⼈物肯定是与克劳塞维茨和拿破仑同⼀时期的康德。在康德看
来，所谓本质的良善的规则，就是那些⾃⼰想要将其推⼴到普世的规
则。根据这个观点，如果某个⼈想要动⼿杀⼈，这时应该先停下来，
经历以下的思考过程：“我现在正要杀掉⼀个⼈。我是不是想要确⽴
⼀条普世规则，规定允许杀⼈？要是确⽴了这样的普世规则，就有可
能有⼈来杀我。所以，不应该有⼀条允许杀⼈的普世规则。由此可
⻅，我也不该杀⼈。”简单来说，康德就是换了⼀种说法来表达⼀条
古⽼的⻩⾦法则：“你们愿意⼈怎样待你们，你们也要怎样待
⼈”（《⻢太福⾳》7：12）。
这听起来似乎简单⽽明显，总之就是想要别⼈怎样对你，你就应该怎
样对⼈。然⽽，在超脱俗世的哲学领域听起来不错的想法，往往很难
移植到残酷现实的历史领域。历史学家会问康德⼀个关键问题，在说
普世规则的时候，到底应怎么定义“普世”。在实际的历史情境中，如
果想要杀掉某个⼈，第⼀步常常是把这个⼈踢出普世的⼈类共同体。
举例来说，针对罗兴亚⼈的极端分⼦就是这么做的。他们有的为佛教
僧侣，当然反对杀⼈，但却把罗兴亚⼈视为次等⼈，他们⾃然不适⽤
这条普世规则。这些极端分⼦在发表的⽂章与访谈中多次把罗兴亚⼈
⽐作野兽、蛇、疯狗、狼、豺，以及其他危险动物。2017年10⽉30
⽇，暴⼒冲突达到⾼峰，⼀位资深的佛教僧侣向军官讲经说法，认为
⾮佛教徒不完全是⼈，所以针对罗兴亚⼈的暴⼒⾏为是可接受的。
作为⼀个思想实验，想象⼀下康德与负责犹太⼈⼤屠杀的阿道夫·艾希
曼之间的会⾯（对了，艾希曼⾃认为是康德主义者）。在艾希曼签署
命令，要把整列⽕⻋的犹太⼈送往奥斯威⾟集中营的时候，康德告诉
他：“你将要杀掉⼏千⼈。你是不是想要确⽴⼀条普世规则，规定允
许杀⼈？要是确⽴了这样的普世规则，你和你的家⼈也可能会被杀
死。”艾希曼说：“没这回事，我并⾮想杀掉⼏千个⼈，我只是想杀掉
⼏千个犹太⼈⽽已。如果你问的是，我想不想确⽴⼀条普世规则，说
杀犹太⼈完全可⾏，那我可是再赞成不过。对我和我的家⼈来说，这
条普世规则并不会让我们被杀，我们可不是犹太⼈。”
康德可能会回应艾希曼说在定义实体的时候，必须选⽤最普世适⽤的
那个定义。所以如果某个实体可以被定义为“犹太⼈”或“⼈类”，就该
选⽤更普世适⽤的“⼈类”⼀词。然⽽，纳粹意识形态最⼤的特点，就
是从根本上否定犹太⼈是⼈。除此之外，也请注意犹太⼈除了是“⼈
类”，也是“动物”，甚⾄是“⽣物”。⽽由于“动物”与“⽣物”显然⼜是
⽐“⼈类”更普世适⽤的类别，如果真的遵循康德的逻辑，最后我们可
能都必须吃纯素⻝了。因为既然我们是⽣物，不就代表我们应该反对
杀死任何⽣物，包括番茄或阿⽶巴原⾍？
历史上，许多（甚⾄是绝⼤多数）冲突都与身份的定义有关。每个⼈
都会说杀⼈是不对的，但⼜总会认为只有杀了⾃⼰内群体的成员才算
是“杀⼈”，如果杀的是外群体的成员就不算“杀⼈”。然⽽，内群体与
外群体只是存在于主体间的概念，其定义常常源⾃⼀些虚构的故事。
于是，原本⼀⼼追求普世理性规则的义务论，最后往往成为地⽅虚构
故事的俘虏。
如果我们⼀⼼想要追求义务论的那种普世规则，⽽且不是将其套到⼈
身上，⽽是套到计算机头上，义务论引出的这个问题就会变得格外要
命。计算机甚⾄根本不是⽣物。所以如果它们要遵守“你们愿意⼈怎
样待你们，你们也要怎样待⼈”这条规则，那杀死像⼈类这样的⽣物
⼜何妨？⼀台遵守康德的逻辑，⽽且想活下去的计算机，并没有理由
反对“杀死⽣物很可⾏”这样的普世规则，反正这条规则并不会危及⾮
⽣物的计算机。
此外，计算机身为⾮⽣物实体，甚⾄有可能根本不害怕死亡。就我们
所知，死亡是⼀种⽣物现象，可能并不适⽤于⾮⽣物实体。当古代亚
述⼈说要“杀掉”⽂献的时候，也只是打⽐⽅。如果计算机更像⽂件⽽
不像⽣物，根本不在意“被杀”，⼈类⼜是否乐⻅⼀台计算机遵循康德
的逻辑，做出“杀⼈⽆所谓”这样的结论？
有没有哪种⽅法，既能定义计算机该保护哪些对象，⽽不会被⼀些存
在于主体间的错误观念影响？最清楚的建议就是告诉计算机保护所
有“能够感受到痛苦的实体”。⼈之所以会感到痛苦，常常是因为相信
了当地的某种主体间虚构概念，但痛苦本身仍然是个普世存在的现
实。因此，如果以“能够感受到痛苦”来定义是否属于内群体，就能让
道德有个客观⽽普世存在的现实基础。⾃动驾驶汽⻋除了不该杀死任
何⼈类（⽆论是佛教徒还是穆斯林，也⽆论是法国⼈还是意⼤利
⼈），也不该杀死狗和猫，以及未来可能出现的能够感受痛苦的机器
⼈。我们甚⾄还能让这条规则变得更完善，要求⾃动驾驶汽⻋依据不
同⽣物能够感受痛苦的程度，安排保护的顺序。如果⾃动驾驶汽⻋必
须选择是撞死⼀个⼈还是⼀只猫，因为理论上猫感受到的痛苦程度⽐
较低，所以应该选择猫。然⽽，如果真往这个⽅向⾛，我们会发现⾃
⼰已经在⽆意间离开了义务论的阵营，来到了功利主义阵营当中。