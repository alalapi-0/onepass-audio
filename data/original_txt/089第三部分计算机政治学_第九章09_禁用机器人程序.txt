禁⽤机器⼈程序
⾯对算法对⺠主对话的威胁，⺠主制度也不是⽆计可施。⺠主制度能
够也应该做的，就是对⼈⼯智能加以规范，避免⼈⼯智能散播假新
闻，污染⼈类的信息⽹络。哲学家丹尼尔·丹尼特建议，货币市场的传
统规范⽅式可作为借鉴。⾃硬币与纸币发明以来，技术上⼀直都有制
造假币的可能性。假币的存在会破坏⼈⺠对货币的信任，威胁⾦融体
系的⽣存。如果假币充斥市场，⾦融体系就会崩溃。⾦融体系存活数
千年，其⾃保⽅式正是制定法律打击假币，压低假币在流通货币当中
的⽐例，维持⼈⺠对货币的信任。
⽤来处理假币的道理，应该同样适⽤于处理假冒⼈类的问题。要是政
府在假币的处理上态度坚决，认为有必要保护⼈⺠对货币的信任，此
时也该以同样坚决的态度，保护⼈⺠对⼈类的信任。在⼈⼯智能兴起
之前，⼈类就有可能假冒他⼈身份，⽽且社会对这种诈骗⾏为绝不宽
恕。但社会过去并没想过要⽴法禁⽌“假冒⼈类”这种问题，因为过去
没有假冒⼈类的技术。时⾄今⽇，既然⼈⼯智能有了假冒⼈类的能
⼒，就有可能破坏⼈类彼此的信任，使社会结构遭到破坏。因此丹尼
特建议，政府应该果断⽴法禁⽌假冒⼈类，就像过去禁⽌伪造货币⼀
样。
法律不但应该禁⽌深度伪造特定的真实⼈物（如制作假的美国总统的
视频），同时还应该禁⽌⾮⼈类⾏为者冒充⼈类。如果有⼈说这种严
格的规定侵犯了⾔论⾃由，我们应该提醒他们，机器⼈程序并没有⾔
论⾃由。禁⽌⼈类使⽤公共平台是敏感的⾏为，⺠主制度对于这种⾏
为的审查制度应该格外谨慎。但禁⽌机器⼈程序是个再简单不过的议
题：这不会侵犯任何⼈的权利，因为机器⼈程序并不拥有任何权利。
这并不代表⺠主制度必须禁⽌所有机器⼈程序、算法与⼈⼯智能参与
所有讨论。许多对话都欢迎各种数字⼯具加⼊，但前提是不要假冒为
⼈。举例来说，⼈⼯智能医⽣可能对⼈类⾮常有帮助，可以每天24⼩
时注意我们的健康状况，根据每个⼈的健康状况与个性量身打造医疗
建议，并且有⽆限的耐⼼来回答我们的问题。然⽽，⼈⼯智能医⽣永
远不该假装⾃⼰是⼈。
⺠主制度另⼀项可以采取的重要措施，是禁⽌算法在⽆⼈监督的情况
下对关键的公共辩论进⾏筛选和管理。当然，我们还是可以继续使⽤
算法来运⾏各种社交媒体，毕竟这种⼯作显然不是⼈类⼒所能及的。
然⽽，算法究竟根据怎样的原则来决定要屏蔽哪些声⾳、放⼤哪些声
⾳，都必须经过⼈类的审查。审查真实的⼈类观点，绝对需要⼩⼼谨
慎，但我们可以做的是阻⽌算法刻意散播愤怒的情绪。⾄少对于算法
是依据怎样的原则来进⾏筛选，企业应该保持透明。要是企业⽤愤怒
来吸引我们的注意⼒，就得清楚坦陈⾃⼰的商业模式，以及背后可能
存在的政治连接。如果算法会系统性地屏蔽与该企业⽴场不同的视
频，⽤户也该有权得知。
近年来已经有许多⼈提出想法，对⺠主制度该如何监督机器⼈程序与
算法进⼊公共对话建⾔献策，这⾥提到的只是⼀⼩部分。当然，每种
⽅式都各有优缺点，做起来也都不简单。⽽且因为科技发展如此迅
速，各种法规可能很快就会过时。我在这⾥想说的是⺠主制度绝对可
以对信息市场加以规范，⽽且⺠主制度的存亡也正取决于此。天真的
信息观反对监管，认为全然⾃由的信息市场会⾃然⽽然产⽣真相与秩
序。但这与⺠主的实际历史完全是两回事。维护⺠主对话从来都不是
件容易的事，过去所有的⺠主对话场域（从国会与市政厅到报纸与⼴
播）也都需要监管，⽽在⼀个⾮⼈类智能可能主导对话的时代，监管
更应加强。