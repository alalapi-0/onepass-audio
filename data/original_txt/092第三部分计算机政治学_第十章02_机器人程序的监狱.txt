机器⼈程序的监狱
虽然⼈⼯智能有许多⽅⾯有利于中央集权，但专制与极权政权在⼈⼯
智能⾯前也并⾮⽆往不利。⾸先，独裁政权并没有控制⾮⽣物⾏为者
的经验。专制信息⽹络是以恐怖统治为基础的，但计算机并不怕被关
进监狱或被杀。要是某国互联⽹上有⼀个聊天机器⼈程序提到该国在
他国犯下的战争罪⾏，讲了⼀个会冒犯该国领导⼈的笑话，⼜或者批
评了该国的某个政党多么腐败，该政权能对这个聊天机器⼈程序做什
么？特⼯没办法把这个程序关起来，没办法折磨它，也没办法威胁它
的家⼈。该国政府当然能够封锁或删除这个程序，并且试着去找出并
惩罚写出这个程序的⼈，但总之要⽐平常教训⼈⺠困难多了。
过去，计算机还⽆法⾃⾏⽣成内容，⽆法进⾏有智能的对话，⽐如在
VKontakte和Odnoklassniki这些社交平台上，只有⼈类有能⼒提出对
政府的异议。然⽽，如果⽹络空间被塞进了⼏百万个机器⼈程序，都
能⽣成内容、进⾏对话，还能⾃⾏学习与发展，情况将会如何？这些
机器⼈程序的设计者可能是外国⼈⼠或异⻅分⼦，希望传播不同于官
⽅的想法，⽽且当局对此或许⽆计可施。就当局的⽴场⽽⾔，如果在
授权机器⼈程序运作之后，这些程序收集了关于该国现状的各种信
息，找出其中的模式，并逐渐⾃⾏发展出与政府不同的观点，情况岂
不是更糟？
这就是⼀种⼀致性问题。虽然⼈类⼯程师可以尽最⼤努⼒打造出向政
府看⻬的⼈⼯智能，但鉴于⼈⼯智能具有⾃我学习与改变的能⼒，难
保哪天⾛向政府不乐⻅的⽅向。特别有趣的⼀点在于，正如奥威尔在
《⼀九⼋四》所解释的，极权信息⽹络常常都需要依赖双⾔巧语
（doublespeak），例如⼀些极权国家的宪法会做出许多崇⾼的承
诺，⽐如“⼈⼈均应享有思想及⾔论⾃由”“⼈⼈均应享有寻求、接
收、传递、⽣产与散播信息的⾃由”“⼤众媒体之⾃由应受保障，不得
实施审查制度”等等，但⼏乎没有⼈会天真到相信这些承诺的字⾯意
义，⽽计算机并不懂这样的双⾔巧语。如果要求聊天机器⼈程序遵守
极权国家的法律与价值观，它可能会在读了宪法之后，认定⾔论⾃由
是该国的核⼼价值，⽽在该国的⽹络空间待上⼏天，观察整个国家信
息领域发⽣的种种事情之后，这个聊天机器⼈程序就可能会开始批评
该国的政权违反了⾔论⾃由这项核⼼价值。⼈类虽然也会注意到这些
⽭盾，但会因为恐惧⽽不敢明说。聊天机器⼈程序却是看到什么说什
么，哪有什么不敢说的呢？⼈类⼯程师该怎样才能向聊天机器⼈程序
解释，虽然宪法明⽂保障每位公⺠的⾔论⾃由，禁⽌实施审查制度，
但聊天机器⼈程序其实不该相信宪法，也不能提理论与现实之间的差
距？就像曾经有⼈跟我说的，在极权国家⻓⼤的⼈，相信问题会带来
麻烦。但在训练算法的时候，如果要它相信“问题会带来麻烦”这种原
则，算法⼜要怎么学习与发展？
最后，政府如果采取了某项极为失败的政策，后来⼜改变⼼意，常常
就会把失败推到别⼈头上，掩饰⾃⼰的过错。⽽⼈类⼜常常是经过惨
痛的教训，才能学会忘记那些给⾃⼰找麻烦的事实。但我们要怎样才
能训练聊天机器⼈程序，要它赶快忘记那些今天被批得⼀⽂不值，但
在短短⼀年前还是国家官⽅⽴场的政策？这将是极权政权难以应对的
重⼤技术挑战，特别是在聊天机器⼈程序越来越强⼤，也越来越不透
明的情况下。
当然，⺠主政权也会有类似的问题，聊天机器⼈程序可能会说⼀些政
府所不乐⻅的话，或者提出⼀些危险的问题。如果微软或脸书⼯程师
已经尽了最⼤努⼒，聊天机器⼈程序却还是散播种族歧视的⾔论，该
怎么办？⺠主政权的优势，在于就算真的遇上算法不受控制的情况，
处理起来也能够较有余裕。因为⺠主政体“藏在柜⼦⾥的骷髅”可能会
少⼀些，所以就算碰上反⺠主⾔论，⼤体上也能够包容。但极权政权
简直就像在柜⼦⾥藏了整个⻅不得光的墓园，因此完全⽆法承受任何
批评，这种时候，会提出异议的机器⼈程序就会形成极为严重的挑
战。