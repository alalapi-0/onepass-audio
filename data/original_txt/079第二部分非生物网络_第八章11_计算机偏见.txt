计算机偏⻅
有些⼈可能希望，只要赋予计算机更强⼤的能⼒，就能克服各种宗教
与意识形态上的偏⻅。这些⼈或许认为，种族主义、厌⼥、恐同、反
犹太主义等偏⻅并不存在于计算机，⽽是源⾃⼈类的⼼理状况与神话
观点。计算机只关⼼数学，不谈⼼理学或神话。所以如果能够彻底排
除⼈类的成分，就能让算法完全基于数学做判断，摆脱⼼理扭曲或神
话偏⻅的影响。
遗憾的是，许多研究都显示，计算机同样有根深蒂固的偏⻅。虽然计
算机并⾮⽣物实体，也没有意识，但计算机确实拥有类似数字⼼灵的
东⻄，甚⾄可能出现某种计算机间的神话观点，所以同样可能有种族
歧视、厌⼥、恐同或反犹太主义倾向。举例来说，2016年3⽉23⽇，微
软推出⼀款⼈⼯智能聊天机器⼈Tay，它能够⾃由存取推特的内容，
并与⽤户互动。结果不到⼏⼩时，Tay已经开始发表厌⼥与反犹太主
义的推⽂，⽐如“我恨透了⼥权主义者，他们都该在地狱⾥燃烧”“希
特勒是对的，我讨厌犹太⼈”。这些恶毒仇恨的⾔论不断增加，吓坏
了微软⼯程师，迅速将Tay下架——这时距离其被推出才短短16⼩
时。
2017年，麻省理⼯学院教授乔伊·布兰维尼研究了市场上的⼈脸分析算
法产品，发现⾥⾯有点不太明显却极为普遍的种族歧视问题。她指
出，这些算法识别⽩⼈男性⾮常准确，但识别⿊⼈⼥性却⾮常不准
确。举例来说，IBM算法在判断浅肤⾊男性的性别时，错误率只有
0.3%，但判断深肤⾊⼥性的性别时，错误率竟⾼达34.7%。作为定性
测试，布兰维尼拿出⾮裔美籍⼥性传教⼠索杰纳·特鲁斯（特鲁斯以
1851年的演说《我难道不是⼥⼈吗？》⽽闻名）的照⽚，请算法做判
断。那些算法竟判断特鲁斯是⼀位男性。
布兰维尼是加纳裔美籍⼥性，她拿了另⼀套⼈脸分析算法来对⾃⼰做
识别，结果那套算法根本⽆法“看⻅”她肤⾊较深的脸。在这种情境
中，所谓“看⻅”指的是能够判断画⾯中有⼀张⼈脸，例如，⼿机摄像
头就会利⽤这种功能来判断该聚焦在哪⾥。那套算法很容易就能看⻅
肤⾊较浅的⼈脸，却看不到布兰维尼的脸。布兰维尼戴上了⼀个⽩⾊
⾯具，那套算法才忽然意识到原来眼前有张⼈脸！
这到底是怎么回事？⼀种可能是这些算法背后有⼀群有种族歧视倾向
⼜厌⼥的⼯程师，写算法的时候就是想要歧视⿊⼈⼥性。这种答案虽
然不能说全⽆可能，但⽆论是⼈脸识别算法的例⼦还是微软的Tay，
事实并⾮如此。事实上，这些算法是从那些训练它们的数据⾥学到了
种族歧视和厌⼥偏⻅。
为了说明为什么会有这种状况，得来解释⼀下算法的历史。⼀开始，
算法没有办法靠⾃⼰来学习东⻄。⽐如在20世纪⼋九⼗年代，国际象
棋算法所知道的⼀切，⼏乎都是⼈类程序员告诉它的。⼈类写进算法
的，除了国际象棋的基本规则，还包括该怎样评估各种棋局和棋步。
⽐如，当时⼈类就写出⼀条规则告诉算法，牺牲王后来保住兵通常不
是什么好主意。这些早期的算法之所以能够击败⼈类国际象棋⼤师，
只是因为它们能⽐⼈类计算更多棋步、评估更多棋局，仅此⽽已。但
是算法的能⼒有限。如果算法必须依赖⼈类告诉它们关于国际象棋的
⼀切秘密，如果⼈类程序员不知道某些事情，那么它们产⽣的算法就
不太可能知道。
但随着机器学习这个领域的发展，算法变得越来越独⽴。机器学习最
基本的原则，就是要让算法像⼈类⼀样，能够通过与世界互动来教⾃
⼰学会新事物，成为⼀套成熟的⼈⼯智能。虽然各⽅对⼈⼯智能的定
义还有差异，但⼤致来说，要想称得上“⼈⼯智能”，就必须具备⾃⾏
学习新事物的能⼒，⽽不能只是遵循最初⼈类创造者的指示。例如，
现在发展出的棋类⼈⼯智能，⼈类除了游戏的基本规则，已经不会
再“教”它们其他内容，⽽是让它们彻底⾃学，通过分析过去棋局的资
料库，或者不断下新的棋局，从经验中学习。⼈⼯智能并⾮不顾结
果，只是傻傻地不断重复同样的动作，⽽是拥有强⼤的⾃我修正机
制，能够从⾃⼰的错误中学习。
这代表着⼈⼯智能⼀开始就像个“算法宝宝”，虽然没有多少知识，但
拥有巨⼤的潜⼒与运算能⼒。⼈类⽗⺟给它的只有学习能⼒，并让它
能够接触这个资料世界，接着就放⼿让这个“算法宝宝”⾃⼰探索。⽽
与⼈类宝宝⼀样，“算法宝宝”的学习⽅式就是从⾃⼰能接触到的数据
中找出规律模式。如果去摸⽕，会很痛；如果我哭了，妈妈就会来；
如果我牺牲⼀个王后去换⼀个兵，这⼀局可能就会输。通过寻找数据
中的规律模式，“算法宝宝”就能学到更多，包括许多连⼈类⽗⺟都不
了解的事。
然⽽，数据库也会有偏⻅。布兰维尼研究的那些⼈脸分析算法，训练
时⽤的是各种经过标记的线上照⽚资料集，例如，LFW⼈脸识别数据
库（Labeled Faces in the Wild，即“真实世界经过标记的⼈脸”）。这
个数据库的照⽚主要来⾃线上新闻⽂章，⽽⽩⼈男性⼜在新闻中占了
⼤多数，于是整个数据集有⾼达78%的照⽚为男性、84%为⽩⼈。仅
⼩布什⼀个⼈，在整个数据集⾥就出现了530次，⾜⾜是所有⿊⼈⼥性
出现次数的两倍。在另⼀个由美国政府机构建设的数据库中，有超过
75%的照⽚为男性，将近80%为浅肤⾊，深肤⾊⼥性在⾥⾯只占
4.4%。所以，⽤这些数据集训练出的算法虽然很懂得如何识别⽩⼈男
性，却不擅⻓识别⿊⼈⼥性。聊天机器⼈Tay的情况也类似。微软⼯
程师并没有刻意加进什么偏⻅，但让这款⼈⼯智能在推特上接触各
种“有毒”信息⼏⼩时之后，它就成了极端种族主义者。
事情还可能更糟。想要学习，“算法宝宝”除了需要数据，还需要另⼀
样东⻄——⼀个⽬标。⼈类宝宝之所以能学会⾛路，是因为他们想要
到达某个地⽅；狮⼦宝宝之所以能学会狩猎，是因为想要吃东⻄。算
法的学习，也必须有个⽬标。如果是国际象棋，这个⽬标很容易：吃
掉对⼿的国王就⾏了。有了这个⽬标，⼈⼯智能就能发现牺牲王后来
换⼀个兵是个“错”，因为这样⼀来，通常会让算法难以达成⽬标。在
⼈脸识别⽅⾯，⽬标也很简单：能够判断照⽚⼈物的性别、年龄与姓
名，得到与数据库记录相同的结果。要是算法认为照⽚中的⼩布什是
个⼥性，但数据库记录显示其为男性，就代表未能实现⽬标，算法也
会从这个错误中学习。
然⽽，假设你要训练⼀套⽤来招聘的算法，⽬标该怎么确定？算法要
怎么知道⾃⼰犯了错，聘⽤了⼀个“错”的⼈？我们可能会告诉这
套“算法宝宝”，它的⽬标是找到会在公司⾄少⼯作⼀年的⼈。企业显
然并不希望投⼊⼤量时间与⾦钱，培养⼀个⼲⼏个⽉就辞职或被解雇
的员⼯。这样确⽴⽬标之后，就该看看数据了。在国际象棋⾥，算法
只需要和⾃⼰对弈，就能产⽣⽆穷⽆尽的新数据。但就业市场没办法
这么⼲。没有⼈能够真正创造⼀个完整的假想世界，让“算法宝宝”雇
⽤与解雇各种假想员⼯，再从经验⾥学到教训。“算法宝宝”只能以真
实⼈类的现有数据库进⾏训练。狮⼦宝宝要想认识什么是斑⻢，主要
依靠在现实的草原上找出斑⻢的花纹模式；“算法宝宝”要学会什么是
好员⼯，主要依靠的是在现实的企业⾥找出好员⼯的⾏为模式。
但很遗憾，如果现实的企业中本来就存在⼀些根深蒂固的偏⻅，“算
法宝宝”很可能就会学习这种偏⻅，甚⾄将其放⼤。举例来说，算法
如果基于现实数据创建“好员⼯”模型，很有可能认定⽼板的侄⼦⽆论
资质如何，都是最好的员⼯。因为过去的数据清楚地表明，⽼板的侄
⼦通常只要求职就能被录⽤，⽽且很少被解雇。“算法宝宝”会找出这
样的模型，学会任⼈唯亲。算法如果负责⼈⼒部⻔，就会认定⽼板的
侄⼦是⼀流⼈选。
同样，如果在⼀个厌⼥的社会⾥，企业⽐较喜欢雇⽤男性⽽⾮⼥性，
那么算法⼀旦使⽤现实数据进⾏训练，就很难摆脱这种偏⻅的影响。
亚⻢逊在2014—2018年尝试研发筛选求职申请的算法时，就确实出现
了这种情况。那套算法在学习了过去求职成功与失败的申请资料之
后，只要申请表⾥有“⼥性”⼀词，或求职者毕业于⼥⼦⼤学，就会系
统性地进⾏扣分。因为现有数据显示，此类求职者被录⽤的概率较
低，所以算法对她们产⽣了偏⻅。算法觉得⾃⼰发现了现实世界的客
观事实：从⼥⼦⼤学毕业的求职者资质较差。事实上，它只是内化，
并且强制落实了厌⼥的偏⻅。亚⻢逊试图解决这个问题，但以失败告
终，最后直接放弃了这个项⽬。
训练⼈⼯智能⽤的数据库，有点⼉像是⼈类的童年。⼈类在童年的经
历、创伤与美好回忆，会陪伴我们⾛完⼀⽣。⼈⼯智能也有童年经
历。算法甚⾄会像⼈类⼀样，受他⼈偏⻅的影响。想象⼀下，算法在
未来的社会⽆所不在，除了能⽤来筛选求职者，还能⽤来帮助学⽣选
专业。由于现实中既有的厌⼥偏⻅，80%的⼯程师职位都由男性担
任。在这样的社会，负责招聘新⼯程师的算法不但可能复制这种既有
偏⻅，还会进⼀步影响那些推荐⼤学专业的算法。如果⼥学⽣发现，
既有数据显示她不太可能找到⼯程师的⼯作，她就会降低读⼯程专业
的意愿。“⼥性不擅⻓⼯程学”原本只是⼀种存在于⼈类主体间的错误
观念，现在却有可能演变成⼀种存在于计算机间的错误观念。如果我
们不从源头消灭这种偏⻅，计算机就很可能将其延续和放⼤。
然⽽，摆脱算法偏⻅的难度或许不低于摆脱⼈类的偏⻅。在算法经过
训练之后，⼈类想要消除算法的训练痕迹，可得花上⼤把的时间和精
⼒。有时候，我们宁可直接放弃⼀套已经产⽣偏⻅的算法，另找⼀个
偏⻅较少的数据集，重新训练⼀套全新的算法。然⽽，哪⾥才能找到
完全没有偏⻅的数据集？
本章与前⼏章所谈到的算法偏⻅，很多都有⼀个同样的基本问题：计
算机觉得⾃⼰找出了某些关于⼈类的真相，事实上却只是把⼀套秩序
硬套在⼈类头上。社交媒体算法以为⾃⼰发现了⼈类喜欢感到愤慨，
但事实上，正是算法让⼈产⽣与接收到更多的愤慨情绪。这种偏⻅⼀
⽅⾯是由于计算机低估了⼈类的能⼒，另⼀⽅⾯也是因为计算机低估
了⾃⼰影响⼈类的能⼒。即使计算机发现⼏乎所有⼈都有某种⾏为⽅
式，也不代表⼈类⼀定有这样的⾏为。搞不好这正意味着计算机⿎励
这种⾏为，惩罚其他⾏为。计算机如果以更准确，也更负责的观点来
看这个世界，就得把⾃⼰的⼒量与影响也考虑进去。要实现这样的⽬
标，⽬前正在设计计算机的⼈就必须接受⼀个事实：他们正在做的
事，不是在制造新的⼯具，⽽是在释放新的独⽴⾏为者，甚⾄可能是
全新的神。