⺠主之路
20世纪末，局势已经相当明朗，帝国主义、极权主义与军国主义绝不
是建⽴⼯业社会的理想⽅式。⾃由⺠主制度虽然有种种缺陷，却仍然
是更好的选择。⾃由⺠主制度的⼀⼤优势，就在于拥有强⼤的⾃我修
正机制，能够避免过度狂热，也保留了发现⾃身错误、改变⾏动⽅针
的能⼒。由于我们⽆法预测新的计算机⽹络究竟会如何发展，如果想
要避免21世纪⾛向灾难，最好的办法就是维持⺠主的⾃我修正机制，
让我们在发展的过程中随时发现并修正各种错误。
然⽽，⾃由⺠主制度还能在21世纪存活吗？这⾥指的并不是特定国家
⺠主制度的命运（各国的⺠主制度会受到独特发展和当地运动的影
响），⽽是就整体⽽⾔，⺠主制度与21世纪的信息⽹络结构能否兼
容。我们曾在第五章提到，⺠主制度是仰赖信息科技才得以存在的，
⽽⼈类历史上的⼤部分时间根本不可能出现⼤规模的⺠主。21世纪的
信息科技，会不会再次让⺠主制度成为⼀个不切实际的选项？
这⾥的⼀个潜在威胁是，新的计算机⽹络铁⾯⽆私、不讲情⾯，很可
能会抹杀⼈类的隐私，⽽且在它奖惩⼈类的时候，被评判的除了我们
的⾔⾏，还包括我们的思想与感受。在这种情况下，⺠主制度还能存
活吗？如果政府（或某家企业）能够⽐我更了解我⾃⼰，⽽且还能在
微观上管理我的⼀切⾏为与思想，就等于是对社会有了极权般的掌
控。在这种情况下，就算还是定期举⾏选举，也只能算是专制政权的
表⾯仪式，⽽⽆法真正对政府权⼒有所制衡。因为在这种情况下，政
府能运⽤强⼤的监控权⼒和对每个公⺠最深⼊的了解，操弄公众舆论
到⼀个前所未有的程度。
然⽽，我们绝不能光是因为计算机有能⼒创造出全⾯监控制度，就认
为这种制度已经不可避免。科技的发展很少是绝对不可避免的。在20
世纪70年代，丹⻨与加拿⼤等⺠主国家本来也可以成⽴独裁政权，建
⽴⼀⽀由特⼯与线⼈组成的⼤军来监控公⺠，维护社会秩序。但这些
国家选择不这样做，事实证明，这是正确的选择。丹⻨与加拿⼤的国
⺠更加快乐，不仅如此，根据⼏乎所有能想到的社会与经济指标进⾏
评判，这些国家的表现都更为出⾊。同样，在21世纪，虽然确实有可
能做到持续监控所有国⺠，但这并不代表国家别⽆选择，也不代表这
种做法在社会或经济上有道理。
对于这些新的监控技术，⺠主国家可以选择有节制地运⽤，以不侵犯
公⺠隐私与⾃主权的⽅式，为公⺠提供更好的医疗保健与安全保障。
并不是每个⾦苹果⾥⾯都⼀定藏着毁灭的种⼦，新科技不⼀定都得带
有什么寓⾔教训。有时候，⼤家想到新科技，会以为只能在有⽆之中
做选择。想要更好的医疗保健，就必须牺牲隐私。但事情并⾮如此。
我们可以，也应该在依然保有部分隐私的情况下，争取到更好的医疗
保健。
有许多图书⽤整本的篇幅谈论⺠主制度怎样才能在数字时代存在下去
且繁荣兴盛。如果我们只⽤短短⼏⻚的篇幅，绝不可能理清那些错综
复杂的建议⽅案，也不可能全⾯讨论其各⾃的优缺点。这样的尝试甚
⾄可能会有反效果。如果我们觉得⾃⼰被⼤量不熟悉的技术细节淹
没，就有可能变得绝望或冷漠。如果我们只是想讲计算机政治学的⼊
⻔概述，就该让事情越简单越好。如果是领域专家，绝对值得投⼊毕
⽣精⼒来讨论其中细节，⾄于我们这些普通⼈，该做的就是了解⼀下
⺠主政体能够也应该遵循的基本原则。这⾥想说的重点在于，这些原
则其实既不新鲜，也不神秘。⼏百年前甚⾄⼏千年前，我们就知道这
些原则，现在只是把这些原则再应⽤于计算机时代的新现实。
第⼀个⺠主原则是为善。如果计算机⽹络要收集关于我的信息，必须
是⽤来帮助我，⽽不是操纵我。⽬前已经有许多传统官僚体系（例如
医疗保健系统）成功采⽤了这个原则。以我们和家庭医⽣的关系为
例，经过多年的治疗，家庭医⽣⼿中可能拥有⼤量关于我们的隐私信
息，包括病情、家庭⽣活情况、性癖好、不健康的习惯等等。或许我
们并不希望让⽼板知道我们怀孕，不想让同事知道我们得了癌症，不
想让另⼀半知道我们有了外遇，但为了⾃⼰的健康，我们会向医⽣坦
诚相告。医⽣要是把这些信息卖给第三⽅，不仅不道德，还会犯法。
就律师、会计师或治疗师⼿上的信息⽽⾔，情况也⼤致如此。这些⼈
受我们所托，取得关于我们个⼈⽣活的信息，就应该负起受托⼈的责
任，按照我们的最佳利益⾏事。这是⼀个理所当然的古⽼原则，⽽我
们为什么不把这个原则延伸到计算机领域和算法上？或许就从⾕歌、
百度和TikTok那些强⼤的算法开始？⽬前，这些⼤数据平台的商业模
式存在严重问题。⼀般来说，我们需要向医⽣和律师⽀付费⽤以换取
服务，但我们通常不需要付钱给⾕歌和TikTok。这些平台赚钱的办
法，就是靠着销售我们的个⼈信息。这种商业模式⼤有问题，要是在
其他情境，我们⼏乎不可能容忍。举例来说，我们⼤概不会为了拿到
免费的运动鞋，就把⾃⼰所有的私⼈信息都提供给耐克公司，还允许
耐克公司随意使⽤。但是，为什么我们为了免费的电⼦邮件服务、社
交关系和娱乐，就愿意让那些科技巨头掌握我们最隐私的数据？
如果科技巨头⽬前的商业模式⽆法负起受托⼈的责任，政府可以要求
它们回归相对传统的商业模式，也就是让⽤户以⾦钱（⽽⾮数据）来
⽀付服务费⽤。或者，某些⾮常重要的数字服务，应该让所有⼈都能
免费使⽤。对此，我们有个现成的榜样：医疗保健与教育。公⺠在仔
细思考后，可以要求政府免费提供基本数字服务，经费由税收⽀出。
许多政府现在正是这样提供着免费的基本医疗保健与教育服务。
能够保护⺠主、避免极权监控崛起的第⼆个原则是去中⼼化。⺠主社
会绝不该允许所有信息集中在⼀处，不管是政府还是⺠间企业。当
然，如果成⽴⼀个国家医疗数据库，收集公⺠信息来更好地服务于医
疗保健、疫情防控或新药研发，这对⼈⺠极为有益。但如果把这个数
据库与警⽅、银⾏或保险公司的数据库整合，就会变得极为危险。虽
然这样可能让医⽣、银⾏业者、保险业者与警⽅做事更有效率，但这
种⾼效也很容易铺平⼀条通往极权的道路。⺠主制度想要存活的话，
效率低⼀点⼉并⾮坏事，反⽽是⼀件好事。如果想要保护个⼈的⾃由
与隐私，最好还是别让警察和上司对我们⽆所不知。
此外，让许多数据库与信息渠道独⽴存在，也有助于维持强⼤的⾃我
修正机制。⾃我修正机制需要不同的机构制度互相制衡。政府、法
院、媒体、学界、⺠间企业，以及⾮政府组织，都可能犯错、可能贪
腐，因此都该由其他机构来制衡监督。⽽为了彼此监督，这些机构就
必须拥有独⽴获取信息的能⼒。要是所有报纸都只从政府那⾥取得信
息，就不可能揭露政府的贪腐内幕。要是学界的研究都只能依赖单⼀
商业巨头的数据库，学者还敢批评该公司的运作吗？⽽且，如果只有
单⼀数据库，想要审查就会易如反掌。
第三个⺠主原则是相互性。如果⺠主制度打算加强对个⼈的监控，就
必须同时加强对政府与企业的监控。税务或福利机构收集更多关于⺠
众的信息，并不⼀定是坏事，反⽽可能有助于提升税务与福利制度的
效率与公平性。但我们不想看到的是所有信息的流动都是⾃下⽽上
的。例如，亚⻢逊与TikTok简直太了解我的个⼈偏好、购买⾏为与个
性了，但我却对它们的商业模式、缴税政策与政治⽴场⼏乎⼀⽆所
知。它们到底是怎么赚钱的？是否正常纳税？是不是听令于哪个政治
领主？或者有哪些政客被它们操纵？
⺠主需要达到平衡。政府与企业常常会研发各种应⽤程序与算法，作
为⾃上⽽下的监控⼯具。算法也可以轻松变成⾃下⽽上的强⼤⼯具，
提升政府的透明度，强化问责制，揭露企业贿赂与逃税的⾏径。要是
在政府和企业更了解我们的同时，我们也能更了解它们，双⽅就能保
持平衡。这不是什么新鲜的想法。在整个19世纪和20世纪，⺠主政府
对公⺠的监控明显加强；20世纪90年代的意⼤利或⽇本政府对公⺠的
监控程度，绝对会让专制的罗⻢帝国皇帝或⽇本幕府将军感到⽆⽐羡
慕。然⽽，正是因为政府的透明度与问责制同时有所改善，意⼤利与
⽇本依然保持了⺠主。相互监督是维持⾃我修正机制的另⼀个重要因
素。如果公⺠能更了解政客与企业家都在做些什么，也就更容易追究
责任、纠正错误。
第四个⺠主原则，是监控系统必须永远保留让⼈改变与休息的空间。
在⼈类历史上，压迫的形式分为两种：剥夺改变的能⼒和剥夺休息的
机会。例如，印度教的种姓制度依据神话将⼈类划分为严格的等级，
如果有⼈想要改变⾃⼰的种姓，简直就像是要挑战众神、违抗宇宙的
正确秩序。⾄于现代殖⺠地与类似巴⻄、美国这些国家的种族主义，
也是依据类似的神话，认为神或⾃然把⼈类分成严格区分的种族群
体，如果有⼈⽆视种族，或是想要让种族混杂，就是违背神或⾃然的
法则，可能使社会秩序崩溃，甚⾄让⼈类⾛向毁灭。
在光谱的另⼀个极端，极权政权则相信⼈类有⼏乎⽆穷的改变潜⼒，
觉得只要通过⽆情的社会控制，就连各种根深蒂固的⽣物特征（例如
本位主义、对家庭的依附）也能被连根拔起，创造出新的⼈类。
要向⼈⺠强加种姓制度或极权的再教育运动，关键在于由国家特⼯、
宗教⼈员或邻居来加强对⼈⺠的监控。⽽新的监控技术，特别是与社
会信⽤体系相结合的监控技术，就可能逼迫⼈⺠接受新的种姓制度，
或者根据上级的最新指示，不断改变⾃⼰的⾏为、思想与个性。
因此，⺠主社会如果采⽤强⼤的监控技术，都得⼩⼼避免⾛向太过刻
板或弹性过⼤的极端。假设国家推出⼀种医疗保健制度，决定⽤算法
来监控我的健康。这个制度如果处在刻板僵化的极端，就可能会不由
分说地要求算法预测我可能出现的疾病。于是算法根据我的基因数
据、医疗记录、社交媒体活动、饮⻝与⾏程安排得出结论，认为我在
50岁患上⼼脏病的可能性⾼达91%。我的保险公司如果相信了这套刻
板僵化的算法，就可能提⾼我的保费。银⾏如果相信了这个结论，就
可能不愿意贷款给我。我的交往对象如果相信了这个结论，就可能不
愿意和我结婚。
但我们不该以为，⽤这种刻板僵化的算法就能找出关于我的真相。⼈
体绝不是⼀种⼀成不变的物质，⽽是⼀个会不断成⻓、衰败、适应的
复杂⽣物系统。我们的⼼智也在不断流动，各种想法、情绪与感受常
常倏忽⽽来、短暂暴发，再平静消失。我们的⼤脑只要⼏个⼩时就能
形成新的突触。举例来说，光是阅读这段⽂字，就会让你的⼤脑结构
稍微有点⼉改变，⿎励神经元建⽴新的连接，或放弃旧的连接。现在
的你，已经和刚开始读这段的时候有点⼉不⼀样了。甚⾄在基因层
⾯，改变的弹性也相当惊⼈。虽然个⼈的DNA这辈⼦不会改变，但表
观遗传与环境因素却能让相同基因的表现⼤不相同。
所以，假设现在换成另⼀种医疗保健制度，或许对算法的要求就不是
预测我的疾病，⽽是协助我设法预防疾病，那么这种⽐较有弹性的算
法，即使与先前的刻板算法使⽤的是完全相同的数据，也不会预测我
会在50岁时患上⼼脏病，⽽是为我量身定制建议，让我知道该如何饮
⻝、做些什么规律性的运动。在破解我的DNA密码之后，这种有弹性
的算法并不是要去找出我早已注定的命运，⽽是协助我改变未来。这
样⼀来，保险公司、银⾏与交往对象⼤概也不会那么轻易地抛弃我
了。
但我们在拥抱弹性算法之前，也得注意它的缺点。⼈⽣在世，要学会
在“提升⾃⼰”与“接受⾃⼰”之间找到平衡。如果弹性算法的背后是野
⼼勃勃的政府和残忍冷酷的企业，算法就可能成为⼀位暴君，⽆情地
要求我们少吃多动、改变喜好、调整习惯，否则就要和我们的上司打
⼩报告，或者降低我们的社会信⽤评分。史上有各种严苛的种姓制
度，总在否定⼈类改变的能⼒，也有许多独裁者，妄图重塑⼈类，如
同捏塑黏⼟⼀般。在这两种极端之间找到正确的路，是⼀项永⽆⽌境
的任务。我们如果真的决定允许国家的医疗保健制度对我们拥有强⼤
的⽀配权，就必须同时为它安排强⼤的⾃我修正机制，才能避免算法
太过刻板僵化或者太过苛刻。