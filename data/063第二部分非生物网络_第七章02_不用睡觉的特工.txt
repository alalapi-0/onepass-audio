不⽤睡觉的特⼯
如果⼀切监控只能靠⼈的眼睛、⽿朵与⼤脑（就像约瑟费斯库上班时
旁边坐着的那位特⼯），那么即使像约瑟费斯库这样的⾸要监控⽬标
也会保有⼀点⼉隐私，特别是没⼈能看到他的脑⼦在想什么。然⽽，
正是约瑟费斯库这些计算机科学家的研究，让事情出现了变化。1976
年，约瑟费斯库桌上的那台计算机虽然还很原始，但已经⽐旁边椅⼦
上坐着的国安局特⼯更懂得怎么处理数字了。⽽到2024年，计算机⽹
络已经⽆所不在，有能⼒每天24⼩时监控全国公⺠，⽽且不需要雇⽤
和培训数百万的⼈类特⼯，只要靠着数字特⼯就能做到。⽹络甚⾄不
需要⾃⼰负担这些数字特⼯的成本：公⺠不但⼼⽢情愿地付钱，⾛到
哪⾥还都带着它们。
那位监控约瑟费斯库的特⼯并不会跟着约瑟费斯库进厕所，在约瑟费
斯库做爱的时候也不会坐在床边。但我们现在的智能⼿机却常常能做
到这⼀点。此外，有很多在约瑟费斯库的时代与计算机⽆关的活动
（⽐如看新闻、和朋友聊天、买东⻄吃），现在都是在线上完成的，
因此⽹络也更容易知道我们在做些什么、说些什么。我们成了⾃⼰的
线⼈，把⾃⼰的原始数据提供给了⽹络。现在就算是不⽤智能⼿机，
也⼏乎逃脱不了某些摄像头、⻨克⻛或追踪设备的监控，不管是求
职、买票还是看病，甚⾄只是⾛在路上，都常常需要和计算机⽹络互
动。⽬前⼤多数⼈类活动都是通过计算机⽹络来联结的，⼏乎所有⾦
融、社会或政治交易都离不开计算机。因此，就像伊甸园⾥的亚当和
夏娃，我们也躲不开云端的眼睛。
计算机⽹络既不需要⼏百万的⼈类特⼯来监控我们，也不需要⼏百万
的⼈类分析师来找出我们这些数据的意义。国家机构⾥的那⽚纸海并
不会⾃我分析，但现在的计算机有了机器学习与⼈⼯智能的魔⼒，已
经能够⾃⾏分析它们收集来的⼤部分信息。⼀般以英语为⺟语的⼈每
分钟能够阅读⼤约250个英⽂单词。所以分析师如果每天轮班12⼩时，
整年不放假，在他40年的职业⽣涯中，⼤概可以阅读26亿个英⽂单
词。但在2024年，像ChatGPT与Meta公司的Llama这些语⾔算法，每
分钟就能处理数百万个单词，要“读完”26亿个英⽂单词也花不了⼏⼩
时。这些算法处理图像、录⾳与视频⽚段的能⼒同样是⼈类远远不及
的。
更重要的是，这些算法在海量数据⾥找出规律和模式的能⼒也远远⾼
于⼈类。要找出规律和模式需要两种能⼒：创造准则的能⼒，以及做
出判断的能⼒。举例来说，⼈类分析师如何判断某个⼈是“疑似恐怖
分⼦”，必须格外注意呢？第⼀，他们会创造⼀套通⽤准则，⽐如“读
极端主义的作品”、“与已知的恐怖分⼦交朋友”，以及“拥有⾜以制造
危险武器的技术知识”。第⼆，他们需要判断某个⼈是否符合标准，
从⽽标记为疑似恐怖分⼦。假设某⼈上个⽉在YouTube上看了100部极
端主义影⽚，他有个朋友是已定罪的恐怖分⼦，⽬前还在某个存有埃
博拉病毒样本的实验室⾥攻读流⾏病学博⼠学位，这个⼈该不该被列
⼊“疑似恐怖分⼦”名单？如果他是个⽣物系⼤学⽣，上个⽉看了50部
极端主义影⽚，这⼜该怎么判断呢？
在20世纪70年代的罗⻢尼亚，只有⼈类能够做出这样的判断。但到21
世纪10年代，⼈类越来越多地把这种事交给算法了。2014—2015年，
美国国家安全局启⽤了⼀套名为“天⽹”（Skynet）的⼈⼯智能系统，
它能够依据⺠众的通信、写作、旅⾏与社交媒体发帖形成的电⼦⾏为
模式，判断某⼈是否需被列⼊“疑似恐怖分⼦”名单。据⼀份报告称，
这套⼈⼯智能系统“对巴基斯坦的移动电话⽹络进⾏了⼤规模监控，
再通过⼀套机器学习算法分析5500万⼈的蜂窝⽹络元数据，评估每个
⼈是恐怖分⼦的可能性”。⼀位曾担任美国中央情报局与国家安全局
局⻓的⼈⼠表示：“我们根据元数据杀⼈。”虽然天⽹的可靠性⼀直遭
到严厉批评，但到21世纪20年代，这样的科技已经变得更精密了，采
⽤的政府也越来越多。算法分析⼤量数据之后，就能找出全新的“嫌
疑⼈”判断准则，逮住过去⼈类分析师可能抓不到的漏⽹之⻥。在未
来，算法甚⾄可能只要研究已知恐怖分⼦的⽣活模式，就能创建出⼀
套全新的模型，⽤来判断⼈的偏激程度。当然，计算机仍然可能出错
（这⼀点在第⼋章还会深⼊讨论），把⽆辜的⼈误判为恐怖分⼦，或
者创造出错误的偏激度模型。在更基本的层⾯上，这些算法对于像恐
怖主义这种事物的定义是否真的客观，也值得商榷。各国政权把所有
反对⼈⼠都贴上“恐怖分⼦”的标签，也早就不是⼀两天的事了。所
以，在⼈⼯智能把某⼈标记为“恐怖分⼦”的时候，有可能反映的只是
意识形态上的偏⻅，⽽不是客观的事实。创造准则的能⼒，以及做出
判断的能⼒，都必然与犯错的能⼒密不可分。就算算法没有犯下任何
错误，光是拥有在海量数据⾥找出规律和模式的超⼈类能⼒，就可能
极⼤增强许多恶意⾏为者的⼒量，包括帮助独裁者识别异⻅⼈⼠，或
是协助诈骗犯找出容易上当的“肥⽺”。
当然，这样的模式识别功能也很有可能对社会⼤⼤有利。⽐如，算法
或许可以找出贪腐的政府官员、⽩领罪犯和逃税的公司，还能协助⼈
类卫⽣官员找出对饮⽤⽔的威胁，协助医⽣发现疾病与迅速发展的疫
情，协助警察与社⼯识别受虐的配偶与⼉童。我接下来很少会谈到算
法对官僚体系可能带来的助益，毕竟那些领导⼈⼯智能⾰命的企业家
已经让⼤众听到太多美好的预测了。我将把重点放在算法模式识别可
能带来的危害上，⽬标正是要平衡⼀下那些乌托邦式的愿景。希望我
们既能好好发挥算法可能带来的助益，同时也能控制住算法可能造成
的危害。
但要做到这⼀点，我们就得先看清楚新的数字官僚与过去的⼈类官僚
有何不同。⾮⽣物的官僚能够⼀天24⼩时“在线”，随时随地监控⼈
⺠、与⼈⺠互动。这意味着官僚制度与监控已经不再是我们在特定时
间和地点才会遇到的事。不论是医疗保健系统、治安维护还是企业对
⺠众的操控，都正在成为⽣活中⽆所不在、永远存在的⼀部分，⽽不
是只存在于我们与特定机构互动的时刻（⽐如诊所、警察局、商
场）。这些官僚制度会越来越常伴我们左右，不断观察和分析我们的
⼀举⼀动。就像⻥⽣活在⽔⾥，⼈类也开始活在数字官僚制度之中，
不断吸进呼出各种资料数据。我们的所有活动都会留下⼀道数据痕
迹，这些数据会被数字官僚收集分析以进⾏模式识别。