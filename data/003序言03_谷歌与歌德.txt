⾕歌与歌德
这⾥必须强调，很多时候，拥有更多的信息确实能让⼈更加了解世
界，更明智地运⽤⼿中的⼒量。以⼉童死亡率的⼤幅下降为例，歌德
是全家7个孩⼦⾥的⽼⼤，但只有他和妹妹柯妮莉亚庆祝了7岁⽣⽇。
其他孩⼦多半因病夭折，赫尔曼·雅各布6岁时死于疾病，凯瑟琳娜·伊
丽莎⽩活到4岁，约翰妮·玛丽亚活到2岁，乔治·阿道夫只活了8个⽉，
还有⼀个弟弟来不及取名便胎死腹中。最后柯妮莉亚在26岁病逝，全
家这⼀代只剩歌德⼀⼈。
歌德⾃⼰后来也⽣了5个孩⼦，但除了⻓⼦奥古斯特，其余的孩⼦都在
出⽣后两周内夭折。夭折的原因很可能是歌德和妻⼦克⾥斯典娜的⾎
型不兼容，让她在第⼀次成功怀孕后，体内出现了对抗胎⼉⾎型的抗
体。这种病被称为Rh⾎型不合溶⾎病，⽬前已能有效治疗，死亡率不
到2%，但在18世纪90年代，这种疾病平均死亡率⾼达50%，等于给歌
德后来的4个孩⼦都判了死刑。
18世纪末，歌德家族堪称德国的富裕家庭，但他家这两代的⼉童存活
率只有可怜的25%，12个孩⼦中只有3个活到成年。这个可怕的统计数
据并⾮个例，歌德在1797年写下《魔法师学徒》时，估计德国⼉童只
有50%能活到15岁，⽽且当时全球⼤多数地区的情况⼤概也是如此。到
2020年，全球⼉童有95.6%能活到15岁，这个数据在德国更是⾼达
99.5%。之所以能有这项重⼤的成就，当然是因为收集、分析和共享了
关于⾎型等要素的⼤批医学数据。所以就这个案例⽽⾔，天真的信息
观其实说得没错。
然⽽，天真的信息观并未⻅到事物的全貌，现代历史可不只是⼉童死
亡率降低⽽已。在近⼏个世代⾥，信息⽣产的数量与速度都经历了前
所未有的最⼤增⻓。现在任何⼀部智能⼿机储存的信息量都能超越古
代的整座亚历⼭⼤图书馆，还能让⽤户实时与世界各地⼏⼗亿⼈建⽴
联系。然⽽，随着这些信息以惊⼈的速度传播，⼈类却⽐过去任何时
候都更接近⾃我毁灭。
⼈类坐拥⼤量数据（或许也正是这个原因），却还是在不断向⼤⽓排
放温室⽓体，污染河海，砍伐森林，破坏栖息地，让⽆数物种灭绝，
甚⾄还危及⾃⼰这个物种的⽣态基础。⼈类还在⽣产着越来越强⼤的
⼤规模杀伤性武器，从热核弹到末⽇病毒，⽆所不包。⼈类领导者的
⼿中并不是没有关于这些危险的信息，但他们⾮但没去合作寻找解决
⽅案，反⽽让⼤家越来越接近⼀场全球战争。
这个时候，坐拥更多信息是会让事情变好还是变得更糟，我们很快就
会知道。⽬前，许多企业与政府都在争先恐后地研发⼈类历史上最强
⼤的信息技术——⼈⼯智能。⼀些知名企业家，⽐如美国投资⼈⻢克·
安德森，相信⼈⼯智能最后能够解决⼈类所有的问题。2023年6⽉6
⽇，安德森发表了《为何⼈⼯智能能拯救世界》（Why AI Will Save
the World）⼀⽂，⽂中充满了⼤胆的⾔论，⽐如，“我要告诉⼤家这项
重要的好消息：⼈⼯智能⾮但不会毁灭世界，⽽且还可能拯救世
界”“⼈⼯智能能让我们关⼼的⼀切变得更好”。他最后总结道：“⼈⼯
智能的发展与普及，⾮但不是我们该担⼼的⻛险，反⽽是我们对⾃
⼰、对孩⼦、对未来该承担的道德义务。”
雷·库兹⻙尔也同意这种说法，他在《奇点已更为临近》⼀书中表
示：“⼈⼯智能这项关键技术，将让⼈类得以应对各种迫在眉睫的挑
战，包括克服疾病、贫穷、环境退化，以及⼈类的所有弱点。⽽我们
就该负起道德上的责任，实现新技术的承诺。”库兹⻙尔很清楚这项技
术的潜在危险，也对这些危险进⾏了详尽的分析，但他相信这些危险
都可以被成功化解。
但其他⼈就没那么相信了。除了哲学家与社会科学家，许多重要的⼈
⼯智能专家与企业家（例如约书亚·本吉奥、杰弗⾥·⾟顿、⼭姆·奥特
曼、埃隆·⻢斯克、穆斯塔法·苏莱曼）都警告公众：⼈⼯智能可能会
摧毁⼈类⽂明。本吉奥、⾟顿与许多其他专家在2024年共同撰写的⼀
篇⽂章中指出：“不受控制的⼈⼯智能发展，最后可能造成⼤规模的⽣
命损失与⽣物圈伤害，以及⼈类的边缘化甚⾄灭绝。”⼀项2023年的研
究调查了2778名⼈⼯智能研究者，结果显示，有超过1/3的⼈认为，先
进的⼈⼯智能有⾄少10%的可能会造成等同于⼈类灭绝⼀样可怕的后
果。2023年，包括中国、美国与英国在内的近30个国家和欧盟签署了
关于⼈⼯智能的《布莱切利宣⾔》，其中就承认：“这些⼈⼯智能模型
所具备的最重要的功能可能会造成严重的甚⾄是灾难性的伤害，⽆论
是有意的还是⽆意的。”虽然以上使⽤的是这种仿佛描述世界末⽇的语
词，但专家与政府并不是让⼈联想到那些好莱坞电影的画⾯，好像有
机器⼈造反，在街上奔跑射杀⼈类。这种情节⼀来实在不太可能发
⽣，⼆来只会让⼈们忽略真正的危险。专家真正要警告的是另外两种
情况。
第⼀，⼈⼯智能的⼒量可能会⼤幅加剧⼈类既有的冲突，让⼈类形成
内⽃。正如20世纪冷战时期的铁幕分隔出⼏个彼此敌对的势⼒，21世
纪的硅幕（不再是铁丝⽹，⽽是由硅基芯⽚和计算机代码组成的）也
可能区隔出不同的敌对势⼒，引发⼀场新的全球冲突。这场⼈⼯智能
军备竞赛将会制造出更具破坏性的武器，于是即使只是⼀个⼩⼩的⽕
花，也可能引发灾难性的⼤⽕。
第⼆，硅幕所分隔的或许不是彼此敌对的⼈类，⽽是⼀边为所有⼈
类，另⼀边为我们新的⼈⼯智能霸主。不论在哪⾥⽣活，我们都可能
被⼀张看不透的算法⼤⽹束缚，控制着我们的⽣活，重塑着我们的政
治与⽂化，甚⾄是去改造我们的身体与思想，但⼈类却再也⽆法理解
这些控制着我们的⼒量，更别说加以阻⽌了。如果21世纪真会有某个
极权主义⽹络成功征服世界，其背后的掌控者可能并不是⼈类的独裁
者，⽽是某种⾮⼈类智慧。有些⼈以为，如果⼈类将会迎来极权主义
噩梦，主要来源应该是俄罗斯或后⺠主时代的美国等国，但这是对极
权主义威胁的⼀种误解。事实上，不管是俄罗斯⼈、美国⼈还是其他
⼈，真正⾯对的可能是由⾮⼈类智慧引发的极权威胁。
有鉴于这种危险的严重性，⼈⼯智能应该引起全⼈类的共同关注。虽
然不是每个⼈都能成为⼈⼯智能专家，但我们都该知道，⼈⼯智能是
历史上第⼀个能够⾃⾏做决策、创造新想法的技术。⼈类过去的所有
发明，都只是在为⼈类赋予更强⼤的⼒量：过去的新⼯具⽆论多么强
⼤，使⽤的决定权都握在⼈类⼿中。⼑和炸弹并不会决定要杀死谁，
它们只是不会思考的⼯具，没有处理信息、做出独⽴决策时所必需的
智能。相较之下，⼈⼯智能能够⾃⾏处理信息，因此也就能够代替⼈
类做出决策。⼈⼯智能不是⼯具，⽽是能够做出决策的⾏为者。
由于能够掌握信息，⼈⼯智能就能在各种领域独⽴产⽣新的想法，从
⾳乐到医学⽆所不包。在过去，留声机能播放⼈类谱写的⾳乐，显微
镜能显现⼈体细胞的秘密，但留声机⽆法谱写新的乐曲，显微镜也⽆
法合成新的药物。但⼈⼯智能能够⾃⾏创造艺术，找出新的科学发
现。接下来的⼏⼗年⾥，⼈⼯智能甚⾄可能创造出新的⽣命形式，⽅
式可能是编写遗传密码，也可能是发明某种⾮⽣物的代码，从⽽赋予
⾮⽣物实体⽣命。
当下，就算这场⼈⼯智能⾰命还在萌芽阶段，计算机也做出了各种影
响⼈类的决定：要不要核准某⼈的贷款，要不要雇⽤某⼈来⼯作，要
不要把某⼈送进监狱。这种趋势只会愈演愈烈、越来越快，让我们越
来越难以掌控⾃⼰的⽣活。我们真的能相信计算机算法会做出明智的
决定，并创造⼀个更美好的世界吗？这个赌注可⽐相信魔法扫帚会打
⽔要冒更⼤的⻛险，⽽且这⾥赌上的不只是⼈类的⽣命。⼈⼯智能不
但可能改变⼈类这个物种的历史进程，还可能改变所有⽣命形式的演
化历程。
