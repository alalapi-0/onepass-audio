独裁者的困境
⽐起成为算法的傀儡，接下来⼏年⾥，这个世界上的独裁者还会碰上
更迫切的问题。⽬前的⼈⼯智能系统还没有⼤规模操控政权的能⼒，
但极权政权已经出现了太过信任算法的危机。⺠主政权假设任何⼈都
可能犯错，⽽极权政权假设⾃⼰永远是对的。基于这种假设⽽建⽴起
的政权，相信有绝对正确的天才存在，也不乐⻅创造出强⼤的⾃我修
正机制，⽤以监督那位天才。
到⽬前为⽌，这些政权相信的都是由⼈类组成的领导⼈，也是培育个
⼈崇拜的温床。未来，这样的极权传统也使这些政权做好另⼀种准
备：相信有绝对正确的⼈⼯智能。这不只会给这些政权的公⺠带来灾
难，还可能波及世界其他地区。要是某个负责环境政策的算法犯了离
谱的错误，⼜没有⾃我修正机制能够发现并修正这个错误，事情会如
何发展？要是某个负责国家社会信⽤体系的算法犯了离谱的错误，除
了开始恐吓⼀般⼤众，甚⾄还开始恐吓执政党成员，把所有质疑算法
所制定的政策的⼈都贴上“⼈⺠的敌⼈”这个标签，事情⼜会如何发
展？
独裁者⽆法摆脱的问题，就是⾃我修正机制薄弱，以及下属尾⼤不掉
的威胁，⽽⼈⼯智能的兴起⼜可能让这些问题变得更为严重。对独裁
者来说，计算机⽹络带来的其实是⼀个令⼈⽆⽐苦恼的两难困境。独
裁者如果想要摆脱尾⼤不掉的⼈类下属，可以选择信任理论上绝对正
确的信息技术，但这种时候，他们就可能成为信息技术的傀儡。如果
独裁者想要建⽴⼀个⼈类机构来监督⼈⼯智能，就得⼩⼼这个机构对
独裁者的权⼒造成限制。
即使全球只有极少数独裁者选择信任⼈⼯智能，也可能对全⼈类造成
深远影响。科幻⼩说⾥常常会出现⼈⼯智能不再受控，进⽽奴役或消
灭⼈类的场景，⽽且多半把背景设在⺠主资本主义的社会。这点也不
难理解，毕竟⺠主国家的作家对⾃⼰的社会更感兴趣。然⽽，⼈类如
果要对抗⼈⼯智能，⾥⾯最弱的⼀环⼤概就是独裁者。⼈⼯智能如果
要夺取权⼒，最简单的⽅法不是逃出制造科学怪⼈的实验室，⽽是赶
快去讨好偏执的提⽐略。
这种说法并不是预⾔，⽽是提出⼀种可能。1945年之后，独裁者及其
下属还是能和⺠主政权与公⺠携⼿合作，共同抵制核武器的。1955年7
⽉9⽇，爱因斯坦、罗素等著名科学家及思想家共同发表《罗素-爱因
斯坦宣⾔》，呼吁各个国家的领导⼈应合⼒避免发⽣核战争。这份宣
⾔提到：“我们以⼈类的身份，向⼈类殷切呼吁：请铭记⼈性，并忘
却其余。做到这点，眼前就是通往新天堂的道路；反之，眼前就是共
同毁灭的危机。”⼈⼯智能也是如此。独裁者如果相信⼈⼯智能必定
会让权⼒的天平向⾃⼰倾斜，只能说是愚不可及。只要⼀不⼩⼼，⼈
⼯智能就会夺取权⼒。
